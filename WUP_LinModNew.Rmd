---
title: "linear model from Web"
author: "Esteffani Maldonado"
date: "Fall 2021"
output:
   html_document:
         toc: true
         toc_depth: 5
        
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Read about the data from the website where it is staged.  Then form three regression models; Model1 is SIMS~ARM, Model2 is SIMS~GRIP, and Model3 is SIMS~ARM+GRIP. For each model find a 95% prediction interval of SIMS given a value of 94  for GRIP and 88 for ARM. Compare Model1 with Model3 using anova. Write it up in a markdown document, push the project up to your github account and submit it back to canvas as link. 

 


```{r include=FALSE}
require(tidyverse)
require(tigerstats)
require(knitr)

```

```{r}
data <- read.csv(file="https://onlinestatbook.com/case_studies_rvls/physical_strength/data.txt",sep="",header=TRUE)  

```

## Model 1 SIM~ARMS

### scatterplot

```{r}
plot(SIMS~ARM,data=data)
```
  
In the scatter plot, we can see a positive correlation between arm strength and work simulations. The scatter plot has a fairly consistent bandwidth of 4. The standard deviation of the data could be estimated to be 1.  
   
### Numerical results

```{r}
cor(SIMS~ARM,data=data)
```
There is a correlation of approximately 0.7.

### Inferential  (Build model.1)

```{r}
model.1 <- lm(SIMS~ARM,data=data)
summary.lm(model.1)
```

The equation of the line is:
SIMS = 0.054563(ARM) - 4.095160
The adjusted R-squared value is 0.467. This value means that the ARM variable accounts for less than half of the variation of the SIMS data. The error of the mean model of the equation is reduced by 46.7%. The calculated residual standard error of the data is 1.226. This measures the deviation from the regression line. 

#### Predict at target point

```{r}
mydata = data.frame(GRIP=94,ARM=88)
```
  
```{r}
predict(model.1, mydata, interval="prediction")
```
  
#### scatterplot with model fit
  
```{r}
basicNN <- ggplot(data,aes(y=SIMS,x=ARM))
```

```{r}
basicNN + geom_point() + geom_smooth(method=lm)
``` 


## Model 2 SIM~GRIP

### Now add in scatterplot

```{r}
plot(SIMS~GRIP,data=data)
```
  
In this scatterplot, there is a positive linear correlation because the dots are going uphill towards the right. 
  
### Numerical results 

```{r}
cor(SIMS~GRIP,data=data)
```
  
The correlation between the work simulations and the grip strength is smaller than the correlation between work simulations and arm strength, which was 0.683.

### Inferential  (Build model.2)
  
```{r}
model.2 <- lm(SIMS~GRIP,data=data)
summary.lm(model.2)
```

The equation of the line is: 
SIMS =  0.045463*GRIP - 4.809675. 
The adjusted R-squared value is 0.4053, which is even smaller than the value for the first model. 

#### predict model.2 at target point
  
```{r}
predict(model.2, mydata, interval="prediction")
```
  
When the value of grip is 94, the prediction of the SIMS value is -0.536.
      
#### now add the model fit to our plot for model.2
  
```{r}
basicNT <- ggplot(data,aes(y=SIMS,x=GRIP))
```

```{r}
basicNT + geom_point() + geom_smooth(method=lm)
``` 

## Model 3 SIM~ARM+GRIP

```{r}
model.3 <- lm(SIMS~ARM + GRIP,data=data)
summary.lm(model.3)
``` 
  
The equation is:
SIMS = (.037311 * ARM) + (0.024470 * GRIP) - 5.433871
  
### Numerical results (cor)

```{r}
cor(SIMS~ARM + GRIP,data=data)
```
  
This model has the highest correlation compared to the other two models above with a value of 0.733.
    
### Inferential  (Build 2-dimentional model.3)

```{r}
model.3 <- lm(SIMS~ARM + GRIP,data=data)
summary.lm(model.3)
```

SIMS = (0.037311 * ARM) + (0.024470 * GRIP) - 5.433871
  
#### predict model.3 at target point
  
```{r}
predict(model.3, mydata, interval="prediction")
```  

When the ARM and GRIP values are 88 and 94 respectively, the prediction of SIMS is 0.149.

## Comparing nested models ANOVA Test

### Model.1 vs Model.3

```{r}
anova(model.1,model.3)
```

When the test ran, we got the residual sum of squares for model 1 for ARM, 217.88. When we added ARM + GRIP the number of degrees of freedom decreased by one because we are assessing both ARM and GRIP. With the low p value and the reduction of the sum of squares, we can see a significant statistical difference between them. So the model with the two regressors in it is superior to the model with just one. 

### Model.2 vs Model.3

```{r}
anova(model.2,model.3)
```

Here the p value is even lower than the previous one, which makes sense because we already observed that model.1 is better than model.2. The residual sum of squares is 243, which indicates that model.3 is a better model than model 2, and model.1 is a better model than model.2

## Informally compare Model.1 with model.2

```{r}
anova(model.1,model.2)
```

Even though we don't get a p value, we can see that model.1 has the smaller residual sum of squares. 
